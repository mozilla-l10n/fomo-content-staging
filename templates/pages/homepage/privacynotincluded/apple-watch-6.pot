#
msgid ""
msgstr ""
"POT-Creation-Date: 2021-09-13 07:03:50.701589+00:00\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"

msgctxt "title"
msgid "Apple Watch"
msgstr ""

msgctxt "blurb"
msgid ""
"The Apple Watch still reigns supreme in the world of smart watches. You've got all your email, text, phone calls, music, podcasts, and more right there on your wrist (as long as you have an iPhone, "
"of course). And it tracks lots of health data. There's heart rate, sleep tracking, steps, calories, blood oxygen levels, ECG, fall detection, and more. Apple has a pretty good track record of taking"
" all this very personal data and keeping it safe, which we appreciate."
msgstr ""

msgctxt "worst_case"
msgid ""
"Apple does a pretty good job with privacy and security as a company. They say they don't share or sell your data and Apple takes special care to make sure your Siri requests aren't associated with "
"you, which is great. Apple did face backlash in 2019 when it came to light their contractors were regularly listening in on confidential personal conversations when they were reviewing the voice "
"assistant's recordings. Apple changed their policy so users weren't automatically opted-in to human voice review. Recently, Apple made another <a id=\"a1\">positive change</a> for your Siri voice "
"requests -- many audio requests for things like setting timers or alarms or controlling music will no longer be sent over the internet to their servers, instead processing them directly on the "
"device. This is better for your privacy."
msgstr ""

msgctxt "worst_case"
msgid ""
"This device does track a whole bunch of biometric data including your heart rate, blood oxygen levels, menstrual cycle, hearing, breathing, and your heart's electrical signals. That's a lot of "
"personal information gathered in one place. A reminder, it’s always good to <a id=\"a1\">lock down the privacy</a> on all this data as much as possible."
msgstr ""

msgctxt "worst_case"
msgid ""
"What is not good is what can happen with all this very personal health data if others aren't careful. A recent <a id=\"a1\">report</a> showed that health data for over 61 million fitness tracker "
"users, including both Fitbit and Apple, was exposed when a third party company that allowed users to sync their health data from their fitness trackers did not secure the data properly. Personal "
"information such as names, birthdates, weight, height, gender, and geographical location for Apple and other fitness tracker users was left exposed because the company didn't password protect or "
"encrypt their database. This is a great reminder that yes, while Apple might do a good job with their own security, anytime you sync or share that data with anyone else, it could be vulnerable. I "
"don't know about you, but I don't need the world to know my weight and where I live. That’s really dang creepy."
msgstr ""

msgctxt "how_does_it_use_data_collected"
msgid ""
"Apple says it does not share your data with third parties for commercial or marketing purposes. In June 2021, Apple <a id=\"a1\">announced</a> that it will no longer send Siri requests to its "
"servers, but instead will process them at the device level."
msgstr ""

msgctxt "uses_encryption_helptext"
msgid ""
"Uses encryption in transit and at rest. After Apple recognizes the words “Hey Siri,” what you say is encrypted and sent anonymously to Apple servers without being tied to your Apple ID. Audio "
"samples are only retained if you have opted-in."
msgstr ""

msgctxt "manage_vulnerabilities_helptext"
msgid "Apple has a <a id=\"a1\">bug bounty program</a>, which means that anyone who finds a security issue and discloses it responsibly may get paid."
msgstr ""

msgctxt "tips_to_protect_yourself"
msgid "Restrict the amount of personal information like heart rate data is shared by going to the Apple Watch app on your iPhone under: Privacy &gt; Health"
msgstr ""

msgctxt "tips_to_protect_yourself"
msgid ""
"Be very careful what third party companies you consent to share you health data with. If you do decided to share your health data with another company, read their privacy policy to see how they "
"protect, secure, and share or sell your data."
msgstr ""

msgctxt "personal_data_collected"
msgid "Name, contact information, address"
msgstr ""

msgctxt "biometric_data_collected"
msgid "Heart rate, movement, blood oxygen levels, sleep data, voice recordings if you use voice commands"
msgstr ""

msgctxt "social_data_collected"
msgid "Contact list"
msgstr ""

msgctxt "how_can_you_control_your_data"
msgid ""
"Apple retains personal data only for so long as necessary to fulfill the purposes for which it was collected, including as described in their Privacy Policy or in their service-specific privacy "
"notices, or as required by law. No specific data retention details are provided."
msgstr ""

msgctxt "track_record_details"
msgid ""
"Unfortunately, Apple's security measures did not prevent the <a id=\"a1\">major data leak</a> of 61 million fitness tracker data records, including Apple's Healthkit data, by the third party company"
" GetHealth. In September 2021, a group of security researchers discovered GetHealth had an unsecured database containing over 61 million records related to wearable technology and fitness services. "
"GetHealth accessed health data belonging to wearable device users around the world and leaked it in an non-password protected, unencrypted database. The list contained names, birthdates, weight, "
"height, gender, and geographical location, as well as other medical data, such as blood pressure."
msgstr ""

msgctxt "ai_helptext"
msgid "Some of Apple's AI research can be found at <a id=\"a1\">https://machinelearning.apple.com/</a>."
msgstr ""

msgctxt "ai_what_can_it_do"
msgid ""
"Apple states in its privacy policy, \"Apple does not take any decisions involving the use of algorithms or profiling that significantly affect you.\" Apple employs machine learning in many different"
" ways, from using it to to improve Siri to using it to sharpen the photos that you take."
msgstr ""
