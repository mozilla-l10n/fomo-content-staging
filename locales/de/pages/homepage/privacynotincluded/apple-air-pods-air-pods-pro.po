#
msgid ""
msgstr ""
"POT-Creation-Date: 2021-09-13 07:03:43.699363+00:00\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"X-WagtailLocalize-TranslationID: 648d6281-cb81-4462-9c77-a625be8823a2\n"

msgctxt "title"
msgid "Apple Air Pods &amp; Air Pods Pro"
msgstr "Apple Air Pods & Air Pods Pro"

msgctxt "blurb"
msgid ""
"Things that go in your ears that are always on, always connected, and always listening — seems like there's the possibility something could go wrong. Whether you get the AirPods, AirPods Pro, or the"
" pricey AirPods Max, Apple has a pretty good record when it comes to privacy and security so you should be safe. Now you just have to figure out a way not to lose these pricey little pods."
msgstr ""
"Dinge, die Ihnen ins Ohr gehen, die immer an sind, immer verbunden sind und immer zuhören – es sieht so aus, als könnte etwas schief gehen. Egal, ob Sie die AirPods, AirPods Pro oder die teuren "
"AirPods Max kaufen, Apple hat eine ziemlich gute Bilanz in Bezug auf Datenschutz und Sicherheit, sodass Sie auf der sicheren Seite sein sollten. Jetzt müssen Sie nur noch einen Weg finden, diese "
"teuren kleinen Pods nicht zu verlieren."

msgctxt "worst_case"
msgid ""
"Apple does a pretty good job with privacy and security as a company. They say they don't share or sell your data and Apple takes special care to make sure your Siri requests aren't associated with "
"you, which is great. Apple did face backlash in 2019 when it came to light their contractors were regularly listening in on confidential personal conversations when they were reviewing the voice "
"assistant's recordings. Apple changed their policy so users weren't automatically opted-in to human voice review. Recently, Apple made another <a id=\"a1\">positive change</a> for your Siri voice "
"requests — many audio requests for things like setting timers or alarms or controlling music will no longer be sent over the internet to their servers, instead processing them directly on the "
"device. This is better for your privacy."
msgstr ""
"Apple macht einen ziemlich guten Job mit Datenschutz und Sicherheit als Unternehmen. Sie sagen, dass sie Ihre Daten nicht teilen oder verkaufen, und Apple achtet besonders darauf, dass Ihre Siri-"
"Anfragen nicht mit Ihnen in Verbindung gebracht werden, und das ist großartig. Apple sah sich 2019 mit Gegenreaktionen konfrontiert, als sich herausstellte, dass seine Auftragnehmer regelmäßig "
"vertrauliche persönliche Gespräche mithörten, als sie die Aufzeichnungen des Sprachassistenten überprüften. Apple hat seine Richtlinie geändert, sodass Benutzer nicht automatisch für die Überprüfung"
" der menschlichen Stimme angemeldet wurden. Vor kurzem hat Apple eine weitere <a id=\"a1\">positive Änderung</a> für Ihre Siri-Sprachanfragen vorgenommen – viele Audioanfragen für Dinge wie das "
"Einstellen von Timern oder Weckern oder das Steuern von Musik werden nicht mehr über das Internet an ihre Server gesendet, sondern direkt auf dem Gerät verarbeitet. Dies ist besser für Ihre "
"Privatsphäre."

msgctxt "worst_case"
msgid ""
"Apple did recently suffer a bad <a id=\"a1\">security vulnerability</a> that resulted in spyware that could allow bad actors to record calls and messages and even turn an iPhone or iPad camera and "
"microphone on without the user knowing. Apple did patch the security vulnerability. This is a good reminder that even the best companies can be vulnerable to high level hacking."
msgstr ""
"Apple litt kürzlich unter einer <a id=\"a1\">Sicherheitslücke</a>. Diese führte zu Spyware und ermöglichte es Angreifern, Anrufe und Nachrichten aufzuzeichnen und sogar eine iPhone- oder iPad-Kamera"
" und ein Mikrofon einzuschalten, ohne dass der Benutzer es merkt. Apple hat die Sicherheitslücke gepatcht. Dies ist eine gute Erinnerung daran, dass selbst die besten Unternehmen anfällig für Hacker"
" auf hohem Niveau sein können."

msgctxt "worst_case"
msgid ""
"All in all, your AirPods are probably pretty secure and private. They’re still super easy to lose though, so keep in mind you can turn the <a id=\"a1\">Find My</a> features on. That just means a "
"little more location tracking in your life, which, in this case might be worth it."
msgstr ""
"Alles in allem sind Ihre AirPods wahrscheinlich ziemlich sicher und privat. Sie sind jedoch immer noch sehr leicht zu verlieren. Denken Sie also daran, dass Sie die <a id=\"a1\">„Wo "
"ist“</a>-Funktion aktivieren können. Das bedeutet nur ein wenig mehr Standortverfolgung in Ihrem Leben, was sich in diesem Fall lohnen könnte."

msgctxt "signup_requirement_explanation"
msgid "No sign-up required"
msgstr "Keine Registrierung erforderlich."

msgctxt "how_does_it_use_data_collected"
msgid ""
"Apple says it does not share your data with third parties for commercial or marketing purposes. In June 2021, Apple <a id=\"a1\">announced</a> that it will no longer send Siri requests to its "
"servers, but instead will process them at the device level."
msgstr ""
"Apple gibt an, Ihre Daten nicht zu kommerziellen oder Marketingzwecken an Dritte weiterzugeben. Im Juni 2021 <a id=\"a1\">kündigte Apple an</a>,  keine Siri-Anfragen mehr an seine Server zu senden, "
"sondern diese auf Geräteebene zu verarbeiten."

msgctxt "user_friendly_privacy_policy_helptext"
msgid ""
"Apple has a webpage highlighting its privacy principles and features. Apple begins its privacy policy with a statement of principles. While this statement is very long, it is clearly broken out into"
" relevant topics."
msgstr ""
"Apple unterhält eine Webseite, auf der Datenschutzprinzipien und -funktionen erläutert werden. In der Datenschutzrichtlinie von Apple werden einleitend die Prinzipien dargelegt. Zwar ist diese "
"Einleitung insgesamt sehr lang, allerdings ist sie deutlich in relevante Themengebiete unterteilt."

msgctxt "strong_password_helptext"
msgid "Bluetooth required"
msgstr "Bluetooth erforderlich"

msgctxt "manage_vulnerabilities_helptext"
msgid "Apple has a bug bounty program, which means that anyone who finds a security issue and discloses it responsibly may get paid. <a id=\"a1\">https://developer.apple.com/security-bounty/</a>"
msgstr ""
"Apple hat ein Bug-Bounty-Programm, was bedeutet, dass jeder, der eine Sicherheitslücke entdeckt und diese verantwortungsvoll meldet, dafür bezahlt werden kann. <a "
"id=\"a1\">https://developer.apple.com/security-bounty/</a>"

msgctxt "tips_to_protect_yourself"
msgid "You can say “Hey Siri, stop listening.” to turn off speech recognition for some time"
msgstr "Sie können sagen „Hey Siri, hör auf zuzuhören“, um die Spracherkennung für einige Zeit auszuschalten."

msgctxt "personal_data_collected"
msgid "Name, email, phone number, address"
msgstr "Name, E-Mail, Telefonnummer, Adresse"

msgctxt "biometric_data_collected"
msgid "Voice recordings, if you opt-in"
msgstr "Sprachaufnahmen, wenn Sie zustimmen"

msgctxt "how_can_you_control_your_data"
msgid ""
"Apple retains personal data only for so long as necessary to fulfill the purposes for which it was collected, including as described in their Privacy Policy or in their service-specific privacy "
"notices, or as required by law. No specific data retention details are provided."
msgstr ""
"Apple bewahrt personenbezogene Daten nur so lange auf, wie dies zur Erfüllung der Zwecke, für die sie erhoben wurden, erforderlich ist, einschließlich der in der Datenschutzrichtlinie oder in den "
"dienstspezifischen Datenschutzhinweisen beschriebenen Zwecke, oder wie gesetzlich vorgeschrieben. Es werden keine spezifischen Angaben zur Datenspeicherung gemacht."

msgctxt "track_record_details"
msgid ""
"Apple had a recent serious security vulnerability. From <a id=\"a1\">Firewall Times</a>: \"In September 2021, researchers discovered that a spyware called Pegasus had infected iPhones and other "
"Apple Devices via a ‘zero click exploit’, granting the spyware broad power over a users’ device. Once infected, the spyware could record calls and messages and even turn the device camera and "
"microphone on without the user knowing. Pegasus was produced by the NSO Group, an Israel-based company that sells its spyware to governments such as Mexico and Saudi Arabia. Though this spyware "
"would presumably be used to surveil terrorists and criminal enterprises, these governments have also used it to spy on activists, politicians, and journalists. As of September 13, 2021, Apple has "
"patched the exploit."
msgstr ""
"Apple hatte kürzlich eine schwerwiegende Sicherheitslücke. Zitat aus <a id=\"a1\">Firewall Times</a>: „Im September 2021 entdeckten Forscher, dass eine Spyware namens Pegasus iPhones und andere "
"Apple-Geräte über einen ‚Zero-Click-Exploit‘ infiziert hatte und der Spyware weitreichende Macht über das Gerät eines Benutzers gewährte. Sobald das Gerät infiziert war, konnte Spyware die Anrufe "
"und Nachrichten aufzeichnen und sogar die Kamera und das Mikrofon des Geräts einschalten, ohne dass der Benutzer es merkt. Pegasus wurde von der NSO Group produziert, einem in Israel ansässigen "
"Unternehmen, das seine Spyware an Regierungen wie Mexiko und Saudi-Arabien verkauft. Obwohl diese Spyware vermutlich verwendet werden sollte, um Terroristen und kriminelle Unternehmen zu überwachen,"
" haben diese Regierungen sie auch dazu benutzt, Aktivisten, Politiker und Journalisten auszuspionieren. Seit dem 13. September 2021 hat Apple den Exploit gepatcht."

msgctxt "ai_helptext"
msgid "Some of Apple's AI research can be found at <a id=\"a1\">https://machinelearning.apple.com/</a>."
msgstr "Einige der KI-Forschungen von Apple finden Sie unter <a id=\"a1\">https://machinelearning.apple.com/</a>."

msgctxt "ai_what_can_it_do"
msgid ""
"Apple states in its privacy policy, \"Apple does not take any decisions involving the use of algorithms or profiling that significantly affect you.\" Apple employs machine learning in many different"
" ways, from using it to to improve Siri to using it to sharpen the photos that you take."
msgstr ""
"Apple stellt in seiner Datenschutzerklärung fest: „Apple trifft keine Entscheidungen, die den Einsatz von Algorithmen oder Profiling beinhalten, die Sie erheblich beeinträchtigen.“ Apple setzt "
"maschinelles Lernen auf viele verschiedene Arten ein, von der Verbesserung von Siri bis hin zum Schärfen der von Ihnen aufgenommenen Fotos."

#~ msgctxt "price"
#~ msgid "159 - $249"
#~ msgstr "159 - $249"

#~ msgctxt "uses_encryption_helptext"
#~ msgid ""
#~ "Uses encryption in transit and at rest. After Apple recognizes the words “Hey Siri,” what you say is encrypted and associated with a random identifier without being tied to your Apple ID. Audio "
#~ "samples are only retained if you have opted-in."
#~ msgstr ""
#~ "Nutzt in Transit und Ruhezustand Verschlüsselung. Nach der Ansprache „Hey Siri“, die von Apple erkannt wird, ist alles, was Sie sagen, verschlüsselt und wird mit einem zufälligen Identifikator "
#~ "verknüpft, ohne mit Ihrer Apple ID in Verbindung gebracht zu werden. Audiosamples werden nur gespeichert, wenn Sie Ihre Zustimmung erteilt haben."

#~ msgctxt "blurb"
#~ msgid ""
#~ "Things that go in your ears that are always on, always connected, and always listening — seems like there's the possibility something could go wrong. Fortunately, Apple has a pretty good record when"
#~ " it comes to privacy and security though so you should be safe. Now you just have to figure out a way not to lose these pricey little pods."
#~ msgstr ""
#~ "Sie gehören in die Ohren, sind immer an, immer verbunden und hören immer zu. Klingt, als ob da was schiefgehen könnte? Glücklicherweise hat Apple in der Vergangenheit gezeigt, dass Datenschutz und "
#~ "Sicherheit ernst genommen werden. Sie können also beruhigt sein. Jetzt müssen Sie nur noch herausfinden, wie Sie diese hübschen kleinen Pods nicht verlieren."

#~ msgctxt "worst_case"
#~ msgid ""
#~ "Apple does a good job with privacy and security as a company. They don't share or sell your data and Apple takes special care to make sure your Siri requests aren't associated with you. Apple did "
#~ "face backlash in 2019 when it came to light that their contractors were regularly listening in on confidential personal conversations when they were reviewing the voice assistant's recordings. Apple"
#~ " changed their policy so users weren't automatically opted-in to human voice review. Good work Apple!"
#~ msgstr ""
#~ "Apple leistet im Hinblick auf Datenschutz und Sicherheit gute Arbeit. Ihre Daten werden nicht weitergegeben oder verkauft, und Apple achtet besonders darauf, dass Ihre Siri-Anfragen nicht mit Ihnen "
#~ "in Verbindung gebracht werden. Trotzdem sah Apple sich 2019 mit einer Gegenreaktion konfrontiert, als ans Licht kam, dass Auftragnehmer regelmäßig vertrauliche persönliche Gespräche mithörten, "
#~ "während sie die Aufnahmen des Sprachassistenten überprüften. Apple änderte seine Richtlinien, sodass die Überprüfung von Sprachaufnahmen durch Menschen nicht automatisch eingeschaltet war. Gut "
#~ "gemacht, Apple!"

#~ msgctxt "how_does_it_use_data_collected"
#~ msgid ""
#~ "Apple does not share your data with third parties for commercial or marketing purposes. All of your Siri voice requests are associated to a random identifier, and if you have opted-in to allow Apple"
#~ " to have Voice recordings, Apple disassociates them after 6 months.  Apple does not share data with third parties for commercial or marketing purposes."
#~ msgstr ""
#~ "Apple gibt Ihre Daten nicht zu Werbe- oder Marketingzwecken an Dritte weiter. Alle über Siri getätigten Sprachbefehle werden einer zufälligen Kennung zugeteilt, und wenn Sie Apple Zugriff auf Ihre "
#~ "Sprachaufnahmen gewährt haben, wird die Verbindung zu Ihnen nach sechs Monaten unkenntlich gemacht.  Apple gibt keine Daten zu Werbe- oder Marketingzwecken an Dritte weiter."

#~ msgctxt "strong_password_helptext"
#~ msgid "The device pairs securely via Bluetooth, which does not require a password."
#~ msgstr "Das Gerät verbindet sich sicher über Bluetooth und es wird kein Passwort benötigt."

#~ msgctxt "manage_vulnerabilities_helptext"
#~ msgid "Apple has a bug bounty program, which means that anyone who finds a security issue and discloses it responsibly may get paid. https://developer.apple.com/security-bounty/"
#~ msgstr ""
#~ "Apple hat ein Bug-Bounty-Programm, was bedeutet, dass jeder, der eine Sicherheitslücke entdeckt und diese verantwortungsvoll meldet, dafür bezahlt werden kann. https://developer.apple.com/security-"
#~ "bounty/"

#~ msgctxt "how_can_you_control_your_data"
#~ msgid "You can request that data be deleted. You can go to https://privacy.apple.com/ to get a copy of your data, correct your data, or delete your account."
#~ msgstr "Sie können die Löschung Ihrer Daten beantragen. Auf https://privacy.apple.com/ können Sie eine Kopie Ihrer Daten einholen, Ihre Daten korrigieren oder Ihr Konto löschen."

#~ msgctxt "track_record_details"
#~ msgid ""
#~ "They actually changed their Siri voice recording review practices—from an opt out to an opt-in—when people told them they were unhappy having contractors listen to the recordings. Good for them!"
#~ msgstr ""
#~ "Die Vorgehensweisen für die Prüfung von Sprachaufnahmen über Siri wurden geändert, nachdem Verbraucher geäußert hatten, dass sie nicht damit einverstanden waren, dass Vertragspartner mithören "
#~ "konnten. Seitdem müssen Verbraucher solchen Prüfungen aktiv zustimmen, statt sich aktiv dagegen auszusprechen. Gut gemacht!"

#~ msgctxt "ai_helptext"
#~ msgid ""
#~ "Apple employs machine learning in many different ways, from using it to to improve Siri to using it to sharpen the photos that you take. Apple states in its privacy policy, \"Apple does not take any"
#~ " decisions involving the use of algorithms or profiling that significantly affect you.\" Some of its research can be found at https://machinelearning.apple.com/."
#~ msgstr ""
#~ "Apple nutzt KI auf viele unterschiedliche Arten. Beispielsweise wird KI genutzt, um Siri zu verbessern oder Bilder zu schärfen. In der Datenschutzrichtlinie von Apple heißt es: „Apple trifft keine "
#~ "Entscheidungen, die die Verwendung von Algorithmen oder die Erstellung von Profilen beinhalten, die Sie erheblich beeinträchtigen.“ Hier finden Sie Teile der Forschung des Unternehmens: "
#~ "https://machinelearning.apple.com/"
